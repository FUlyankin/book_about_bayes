
%!TEX TS-program = xelatex
\documentclass[12pt, a4paper, oneside]{extreport}

%%%%%%%%%% Програмный код %%%%%%%%%%
\usepackage{minted}
% Включает подсветку команд в программах!
% Нужно, чтобы на компе стоял питон, надо поставить пакет Pygments, в котором он сделан, через pip.

% Для Windows: Жмём win+r, вводим cmd, жмём enter. Открывается консоль.
% Прописываем easy_install Pygments
% Заходим в настройки texmaker и там прописываем в PdfLatex:
% pdflatex -shell-escape -synctex=1 -interaction=nonstopmode %.tex

% Для Linux: Открываем консоль. Убеждаемся, что у вас установлен pip командой pip --version
% Если он не установлен, ставим его: sudo apt-get install python-pip
% Ставим пакет sudo pip install Pygments

% Для Mac: Всё то же самое, что на Linux, но через brew.

% После всего этого вы должны почувствовать себя тру-программистами!
% Документация по пакету хорошая. Сам читал, погуглите!



%%%%%%%%%% Математика %%%%%%%%%%
\usepackage{amsmath,amsfonts,amssymb,amsthm,mathtools}
\mathtoolsset{showonlyrefs=true}  % Показывать номера только у тех формул, на которые есть \eqref{} в тексте.
%\usepackage{leqno} % Нумерация формул слева



%%%%%%%%%%%%%%%%%%%%%%%% Шрифты %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[english, russian]{babel} % выбор языка для документа
\usepackage[utf8]{inputenc} % задание utf8 кодировки исходного tex файла
\usepackage[X2,TS1, T2A]{fontenc}        % кодировка
\usepackage{cmap}


\usepackage{fontspec}         % пакет для подгрузки шрифтов
\setmainfont{Linux Libertine O}   % задаёт основной шрифт документа

\usepackage{unicode-math}     % пакет для установки математического шрифта
\setmathfont[math-style=upright]{Neo Euler} % шрифт для математики


%%%%%%%%%% Работа с картинками %%%%%%%%%
\usepackage{graphicx}                  % Для вставки рисунков
\usepackage{graphics}
\graphicspath{{images/}{pictures/}}    % можно указать папки с картинками
\usepackage{wrapfig}                   % Обтекание рисунков и таблиц текстом


%%%%%%%%%% Работа с таблицами %%%%%%%%%%
\usepackage{tabularx}            % новые типы колонок
\usepackage{tabulary}            % и ещё новые типы колонок
\usepackage{array}               % Дополнительная работа с таблицами
\usepackage{longtable}           % Длинные таблицы
\usepackage{multirow}            % Слияние строк в таблице
\usepackage{float}               % возможность позиционировать объекты в нужном месте
\usepackage{booktabs}            % таблицы как в книгах!
\renewcommand{\arraystretch}{1.3} % больше расстояние между строками

% Заповеди из документации к booktabs:
% 1. Будь проще! Глазам должно быть комфортно
% 2. Не используйте вертикальные линни
% 3. Не используйте двойные линии. Как правило, достаточно трёх горизонтальных линий
% 4. Единицы измерения - в шапку таблицы
% 5. Не сокращайте .1 вместо 0.1
% 6. Повторяющееся значение повторяйте, а не говорите "то же"
% 7. Есть сомнения? Выравнивай по левому краю!

%  вычисляемые колонки по tabularx
\newcolumntype{C}{>{\centering\arraybackslash}X}
\newcolumntype{L}{>{\raggedright\arraybackslash}X}
\newcolumntype{Y}{>{\arraybackslash}X}
\newcolumntype{Z}{>{\centering\arraybackslash}X}

% межстрочный отступ в таблице
\renewcommand{\arraystretch}{1.2}


%%%%%%%%%% Графика и рисование %%%%%%%%%%
\usepackage{tikz, pgfplots}  % язык для рисования графики из latex'a


%%%%%%%%%% Гиперссылки %%%%%%%%%%
\usepackage{xcolor}              % разные цвета

% Два способа включить в пакете какие-то опции:
%\usepackage[опции]{пакет}
%\usepackage[unicode,colorlinks=true,hyperindex,breaklinks]{hyperref}

\usepackage{hyperref}
\hypersetup{
	unicode=true,           % позволяет использовать юникодные символы
	colorlinks=true,       	% true - цветные ссылки, false - ссылки в рамках
	urlcolor=blue,          % цвет ссылки на url
	linkcolor=black,          % внутренние ссылки
	citecolor=black,        % на библиографию
	pdfnewwindow=true,      % при щелчке в pdf на ссылку откроется новый pdf
	breaklinks              % если ссылка не умещается в одну строку, разбивать ли ее на две части?
}

%%%%%%%%%% Другие приятные пакеты %%%%%%%%%
\usepackage{multicol}       % несколько колонок
\usepackage{verbatim}       % для многострочных комментариев
\usepackage{cmap}           % для кодировки шрифтов в pdf

% свешиваем пунктуацию
% теперь знаки пунктуации могут вылезать за правую границу текста, при этом текст выглядит ровнее
\usepackage{microtype}

\usepackage{enumitem} % дополнительные плюшки для списков
%  например \begin{enumerate}[resume] позволяет продолжить нумерацию в новом списке

\usepackage{todonotes} % для вставки в документ заметок о том, что осталось сделать
% \todo{Здесь надо коэффициенты исправить}
% \missingfigure{Здесь будет Последний день Помпеи}
% \listoftodos --- печатает все поставленные \todo'шки


%%%% Оформление %%%%%%%
% размер листа бумаги
\usepackage[
paperwidth=160mm,
paperheight=220mm,
headheight=14mm,
left=10mm,
right=10mm,
top=20mm,
bottom=20mm
]{geometry}

\usepackage{indentfirst}       % установка отступа в первом абзаце главы!!!

\usepackage{fancyhdr}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\thepage}
\fancyhead[LO]{\leftmark}
\fancyhead[RE]{\rightmark}


\usepackage{setspace}
%\setstretch{1.3}  % Межстрочный интервал
%\setlength{\parindent}{1.5em} % Красная строка.
%\setlength{\parskip}{4mm}   % Расстояние между абзацами
% Разные длины в латехе https://en.wikibooks.org/wiki/LaTeX/Lengths

% \flushbottom                            % Эта команда заставляет LaTeX чуть растягивать строки, чтобы получить идеально прямоугольную страницу
\righthyphenmin=2                       % Разрешение переноса двух и более символов
\widowpenalty=300                     % Небольшое наказание за вдовствующую строку (одна строка абзаца на этой странице, остальное --- на следующей)
\clubpenalty=3000                     % Приличное наказание за сиротствующую строку (омерзительно висящая одинокая строка в начале страницы)
\tolerance=10000     % Ещё какое-то наказание.

\usepackage{bm}
\usepackage{bbm} % шрифт с двойными буквами

% свешиваем пунктуацию
% теперь знаки пунктуации могут вылезать за правую границу текста, при этом текст выглядит ровнее
\usepackage{microtype}

% для эпиграфов
\usepackage{epigraph} 
\setlength\epigraphrule{0pt}
\renewcommand{\textflush}{flushepinormal}

% Внешний вид подписей к картинкам и таблицам
\usepackage[font=small, labelfont=bf]{caption}
\DeclareCaptionLabelSeparator{colon}{\textbf{.} }
\DeclareCaptionLabelFormat{dash}{#1\hspace{.55ex}#2}
\captionsetup[figure]{labelformat=dash}




%%%%%%%%%% Свои команды %%%%%%%%%%
\usepackage{etoolbox}    % логические операторы для своих макросов

% Математические символы первой необходимости:
\DeclareMathOperator{\sgn}{sign}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Corr}{Corr}
\DeclareMathOperator{\E}{\mathop{E}}
\DeclareMathOperator{\Med}{Med}
\DeclareMathOperator{\Mod}{Mod}

\DeclareMathOperator*{\plim}{plim}

\newcommand{\const}{\mathrm{const}}        % const прямым начертанием

%% эконометрические сокращения
\def \hb{\hat{\beta}}
\def \hs{\hat{s}}
\def \hy{\hat{y}}
\def \hY{\hat{Y}}
\def \he{\hat{\varepsilon}}
\def \hVar{\widehat{\Var}}
\def \hCorr{\widehat{\Corr}}
\def \hCov{\widehat{\Cov}}

% Греческие буквы
\def \a{\alpha}
\def \b{\beta}
\def \t{\tau}
\def \dt{\delta}
\def \e{\varepsilon}
\def \ga{\gamma}
\def \kp{\varkappa}
\def \la{\lambda}
\def \sg{\sigma}
\def \tt{\theta}
\def \Dt{\Delta}
\def \La{\Lambda}
\def \Sg{\Sigma}
\def \Tt{\Theta}
\def \Om{\Omega}
\def \om{\omega}

% Готика
\def \mA{\mathcal{A}}
\def \mB{\mathcal{B}}
\def \mC{\mathcal{C}}
\def \mE{\mathcal{E}}
\def \mF{\mathcal{F}}
\def \mH{\mathcal{H}}
\def \mL{\mathcal{L}}
\def \mN{\mathcal{N}}
\def \mU{\mathcal{U}}
\def \mV{\mathcal{V}}
\def \mW{\mathcal{W}}

% Жирные штуки
\def \mbb{\mathbb}

\def \RR{\mbb R}
\def \NN{\mbb N}
\def \ZZ{\mbb Z}
\def \PP{\mbb{P}}
\def \QQ{\mbb Q}

% Карточные масти
\DeclareSymbolFont{extraup}{U}{zavm}{m}{n}
\DeclareMathSymbol{\varheart}{\mathalpha}{extraup}{86}
\DeclareMathSymbol{\vardiamond}{\mathalpha}{extraup}{87}


% Команды первой необходимости
\newcommand{\iid}{\mathrel{\stackrel{\rm i.\,i.\,d.}\sim}}  % ну вы поняли...
\newcommand{\fr}[2]{\ensuremath{^#1/_#2}}   % особая дробь
\newcommand{\ind}[1]{\mathbbm{1}_{\{#1\}}} % Индикатор события
\newcommand{\dx}[1]{\,\mathrm{d}#1} % для интеграла: маленький отступ и прямая d

\newcommand{\indef}[1]{\textbf{#1}}     % выделение ключевого слова в определениях

% бульпоинты в списках
\definecolor{myblue}{rgb}{0, 0.45, 0.70}
\newcommand*{\MyPoint}{\tikz \draw [baseline, fill=myblue,draw=blue] circle (2.5pt);}
\renewcommand{\labelitemi}{\MyPoint}

% для нормального распределения
\newcommand{\expp}[1]{ \exp \left( #1 \right)} 
% для прорисовки нормального распределения
\newcommand\gauss[2]{1/(#2*sqrt(2*pi))*exp(-((x-#1)^2)/(2*#2^2))} 



%%%%%%%%%% Теоремы %%%%%%%%%%
\theoremstyle{plain}              % Это стиль по умолчанию.  Есть другие стили.
\newtheorem{theorem}{Теорема}[section]
\newtheorem{result}{Следствие}[theorem]
% счётчик подчиняется теоремному, нумерация идёт по главам согласованно между собой


\theoremstyle{definition}         % убирает курсив и что-то еще наверное делает ;)
\newtheorem*{definition}{Определение}  % нумерация не идёт вообще

\newtheorem{chudo}{Чудо номер}   % Для первой главы



%%%%%%%%%% Список литературы %%%%%%%%%%

%\usepackage[backend=biber,style=chem-acs,sorting=nty]{biblatex}
% style --- стиль оформления библиографии
% backend --- Движок для сборки. Просто пишите сюда biber. Trust me.
% sorting --- Порядок сортировки в списке. nty = сначала по имени, потом по названию, потом по году выхода статьи. В этот же список можно включить 'a' - по алфавиту,


%\addbibresource{bayes.bib} % сюда нужно вписать свой биб-файлик


%%%%%%%%%% Задачи и их решения %%%%%%%%%%%

\usepackage{answers}

\newtheorem{problem}{\color{myblue} Упражнение}
\Newassociation{sol}{solution}{solution_file}
% sol --- имя окружения внутри задач
% solution --- имя окружения внутри solution_file
% solution_file --- имя файла в который будет идти запись решений
% можно изменить далее по ходу

\setlength{\epigraphwidth}{0.5\textwidth}

\usepackage{pgf,tikz}
\usepackage{mathrsfs}
\usetikzlibrary{arrows}

\begin{document}
	
% \Opensolutionfile{solution_file}[solutions1]


\chapter{Регрессия --- моя профессия}

\epigraph{цитата про слонов}{хз кто автор}

Вы ждали, вы надеялись, вы желали. И вот, наконец, этот момент настал! На подиум выходит она, бесподобная, великолепная, линейная регрессия. Много страниц пришлось прочитать, чтобы наконец то дождаться этого торжественного момента и вкусить её во всей красе. 

\section{А ты точно регрессия?} 

Как уже ни раз говорилось, байесовские методы это не новые модели, а принципиально другой подход к оцениванию, в рамках которого можно оценить любую старую модель. Надо только лишь выразить своё незнание в виде распределения и найти неплохую выборку. Регрссия не является в этом плане исключением. 

Сейчас мы будем иметь дело со слонами. Все формулы будут большими. Простым взглядом со стороны осознать их будет сложновато. Мы призываем читателя взять бумагу, ручку и вывести все результаты вместе с нами. 

Начнём. Пусть у нас есть куча наблюдений и целый один регрессор

\[ y_i = \b x_i + u_i, \qquad u_i \sim \mN(0, \sigma^2) .\]

В такой модели нам необходимо оценить два параметра, коэффициент $\beta$ и дисперсию $\sigma^2$. Предположим, что мы знаем что-то о коэффициенте. Степень нашей уверенности выразим через нормальное распределение. Дисперсия $a$ будет показывать силу нашего незнания,  $\beta \mid \sigma^2 \sim N(0,a)$.

Также будем предполагать, что $\sigma \sim InvGamma(s,r)$.  Почему распределение будет именно таким? Оно выбирается таким по двум причинам. Первая причина заключается в том, что наши деды придумали сопряжённые распределения. В данном случае обратное гамма-распределение сопряжено с нормальным. Это позволит нам получить приятное апостериорное распределение и сделать задачу его поиска ручной. Безусловно, это очень архаичная причина.

Вторая причина выражать свои априорные мысли именно с помощью этого распределения, более модная и интуитивная. Она вытекает из того как именно моделируют распределение времени, прошедшее между несколькими событиями.

\begin{enumerate}
	\item Как помнит внимательный читатель, экспоненциальное распределение, $T \sim Exp(\lambda)$, с плотностью распределения $f(t) \propto e^{-\lambda \cdot t}$ обычно используют для моделирования времени между двумя последовательными событиями, которые произошли в Пуассоновском потоке. На самом деле, экспоненциальное распределение это частный случай гамма-распределения, $Exp(\lambda) = \Gamma(0, \lambda)$. Это дат нам почву для обобщений. 
	
	\item Гамма-распределение, $T \sim \Gamma(s,r)$, с плотностью $f(t) \propto t^s \cdot e^{-r \cdot t}$  можно использовать, чтобы моделировать время между несколькими событиями, так как такое распределение это ни что иное как сумма $s+1$ экспоненциального распределения. Есть два способа доказать это. Первый: вспомнить как ищется распределение суммы двух случайных величин. Вспомнив, можно нащупать формулу. Второй: доказать это через характеристические функции. Мы оставим это читателю в качестве упражнения и в традициях лучших книг не будем публиковать решения \footnote{На самом деле раздражает, когда авторы книг так делают. Многие такие упражнения вообще неочевидно как решаются.}.
	
	\item Обратное гамма-распределение, $T \sim \Gamma^{-1}(s,r)$ с плотностью $f(t) \propto t^{-s} e^{-\frac{r}{t}}$ в таком случае, наверное, описывает частоту серий из нескольких событий в течении какого-то времени.
\end{enumerate}

\todo[inline]{Написать нормально о переходе от времени к частоте и после перейти к дисперсии. Вставить картинок. Сделать нормальных упражнений на гамма-распределение.}

Итак, наша текущая задача --- найти апостериорное распределение. К несчастью, для сопряжённости, просто выбрать нормальное и обратное гамма распределения недостаточно. Для того, чтобы сделать его совсем-совсем приятным, придётся придумать как именно должны между собой соотносится $a$, $r$ и $s$ и ограничить себя тем самым ещё сильнее. 

К счастью, STAN позволяет уйти от всех этих ограничений. Мы связываем себе руки только для того, чтобы вручную решить в этой главе задачу по поиску апостериорного распределения, решить парочку упражнений на регуляризаторы, сделать пару интересных наблюдений и ... всё. Дальше мы спокойно скинем с себя оковы. В прекрасном мире будущего все будут свободны, и у каждого будет по два раба.

Формула байеса говорит нам о том, что 

\[ f(\beta, \sigma \mid y,x) \propto f(y \mid \beta, \sigma^2, x) \cdot f(\beta, \sigma^2 \mid x).\] 

Можно сразу же бросаться в бой и прорываться через огромных слонов с экспонентами, как мы это делали в задачке про Машу и Медведей, но мы немного схитрим и возьмём логарифмы от обеих частей равенства

\[ \ln f(\b, \sigma^2 \mid x,y)  \propto \ln f(y \mid  \b, \sigma^2, x) + \ln f(\b, \sigma^2 \mid x). \] 

Не забываем держать в голове, что нас интересуют только $s,r,\b$ и $\sigma^2$. Всем остальным благодаря магии значка $\propto$ мы смело можем пренебрегать. Всё, что будет утеряно, мы восстановим впоследствии из интеграла. 

Первое слагаемое --- это логарифм нашей функции правдоподобия, второе слагаемое --- логарифм нашей априорной плотности распределения. В наших предположениях $f(\beta,\sigma^2 \mid x) = f(\sigma^2 \mid x) \cdot f(\beta \mid \sigma^2, x),$ и второе слагаемое разваливается на два

\begin{multline*}
\ln f(y \mid  \b, \sigma^2, x) + \ln f(\b, \sigma^2 \mid x) = \\ = \sum \ln f(y_i \mid \b, \sigma^2,x_i) + \ln   f(\sigma^2 \mid x) + \ln f(\beta \mid \sigma^2,x).
\end{multline*}

Всё, что мы сделали должно частично избавить нас от слонов и оставить нам только слонят. У нас были такие вот слоны: 

\begin{align*}
 &f(y_i \mid \b, \sigma^2, x_i) = \frac{1}{\sqrt{2 \pi \sigma^2}} \cdot \expp{-\frac{1}{2\sigma^2} \cdot (y_i - \b x_i)^2} \\ 
 &f(\sigma^2 \mid x) = \frac{r^s}{\Gamma(s)} (\sigma^2)^{-s-1} \expp{-\frac{r}{\sigma^2}} 
 \end{align*}

Стали такие вот слонята: 

\begin{align*}
& \ln f(y_i \mid \b, \sigma^2, x_i) \propto -\frac{1}{2} \ln \sigma^2 - \frac{1}{2 \sigma^2} \cdot(y_i-\b x_i)^2 \\
& \ln f(\sigma^2 \mid x) \propto -(s+1) \ln \sigma^2 - \frac{r}{\sigma^2}
\end{align*}

С нормальным распределением для $\b$ произойдёт точно такая же метаморфоза. Обратите внимание, что из него выскакивает лишнее слагаемое $-\frac{1}{2} \ln a$, на которое нам наплевать. В конечном итоге получаем слонёнка

\begin{multline*}
\sum_{i=1}^n \left( -\frac{1}{2} \ln \sigma^2 - \frac{1}{2\sigma^2} \cdot (y_i - \b x_i)^2 \right) - (s + 1) \cdot \ln \sigma^2 - \\ -  \frac{r}{\sigma^2} +  \underbrace{- \frac{1}{2} \ln a}_{\text{на это нам плевать}} - \frac{(\b - 0)^2}{2 a}.
\end{multline*}

В самом начале мы договорились, что хотим на выходе получить точно такие же апостериорные распределение, нормальное и обратное гамма, но с новыми параметрами, $\mN(\tilde m, \tilde a)$ и $\Gamma^{-1} ( \tilde s, \tilde r)$. 

Новые параметры будут пересчитываться на основании старых и на основании полученных наблюдений.

\begin{equation}\label{we_want}
\text{Мы хотим: } -(\tilde{s} + 1) \cdot \ln \sigma^2 - \frac{\tilde{r}}{\sigma^2} - \frac{1}{2} \cdot \frac{(\b - \tilde m)^2}{\tilde{a}} 
\end{equation}

Попробуем сгруппировать нашего гиперслонёнка и получить  формулы пересчёта. Соберём все, что находится перед $\ln \sigma^2$ вместе 

\[\sum_{i=1}^n \left( - \frac{1}{2\sigma^2} \cdot (y_i - \b x_i)^2 \right) - \left(\frac{n}{2} + s + 1\right) \cdot \ln \sigma^2 - \frac{r}{\sigma^2} - \frac{\b^2}{2 a}.\]

Ничего другого перед $\ln \sigma^2$ уже не возникнет. Сравним то, что мы получили с тем, что мы хотим и сделаем вывод, что $\tilde s = s + \frac{n}{2}$. Первая формула пересчёта обнаружена. 

В нашей формуле есть нераскрытый квадрат разности. Как только мы раскроем его, на нас выпрыгнут $\b$ и $\b^2$. По аналогии мы можем раскрыть скобки перед квадратом в формуле \eqref{we_want}, которую мы жаждем получить. Оставшееся уйдёт в константу.

\begin{tabularx}{\textwidth}{X|X|X}
	\[\b\]& \[ - \frac{1}{2 \tilde a} \] & \[ - \frac{1}{2a} - \frac{\sum x_i^2}{2\sigma^2} \] \\ \hline
	\[\b^2\]& \[ \frac{\tilde m}{\tilde a}\] & \[ \frac{1}{\sigma^2} \sum x_i y_i\] \\ \hline
	\[\text{Осталось}\]&  \[ - \tilde r \cdot \frac{1}{\sigma^2} \] & \[ -\frac{r}{\sigma^2} - \frac{1}{2\sigma^2} \sum y_i^2 \] 
\end{tabularx}

Если просто посмотреть на это один раз со стороны, легко можно не понять откуда взялся результат. Поэтому, ленивый читатель прямо сейчас должен взять ручку и бумагу, вернуться в начало главы и самостоятельно всё вывести, потому что негоже не марать бумагу формулами! А мы, вместе с читателями, которые любят самостоятельно получать монументальные результаты, ещё раз выпишем все формулы пересчёта. 

\begin{align*}
\tilde s = s + \frac{n}{2}   \qquad&  \tilde r = r + \frac{1}{2} \sum y_i \qquad 
\frac{1}{\tilde a} = \frac{1}{a} + \frac{1}{\sigma^2} \sum x_i^2  \qquad  \frac{\tilde m}{\tilde a} = \frac{1}{\sigma^2} \sum x_i y_i 
\end{align*}

Формулы для пересчёта $\tilde s$ и $\tilde r$ получились хорошими. Остальные две формулы содержат $\sigma^2$, которая является гиперпараметром и нам неизвестна. Вспомним о том, что мы хотели наложить на $a$, $r$ и $s$ какие-то дополнительные ограничения, которые позволили бы нам спокойно осуществлять пересчёт. Судя по всему, нам придётся сделать параметр $a$ пропорциональным гиперпараметру $\sigma^2$. Ежеле $a = k \cdot \sigma^2$, то 

\begin{align*}
\frac{1}{\tilde k \sigma^2} = \frac{1}{k \sigma^2} + \frac{1}{\sigma^2} \sum x_i^2  \quad \Rightarrow \quad \frac{1}{\tilde k} = \frac{1}{k} + \sum x^2_i \quad \Rightarrow \quad \tilde k = \frac{k}{\sum x_i^2} \\
\frac{\tilde m}{\tilde k \sigma^2} = \frac{1}{\sigma^2} \sum x_i y_i \quad \Rightarrow \quad  \tilde m = \tilde k \cdot \sum x_i y_i \quad \Rightarrow \quad \tilde m = k \cdot \frac{\sum x_i y_i}{\sum x_i^2}.
\end{align*}

Таким образом, мы получаем удобные формулы для пересчёта параметров апостериорного распределения. Когда наши Деды придумывали это, они понимали, что вывести эти формулы будет нелегко, зато будет легко их использовать. Другими словами, наши Деды восхищались Суворовым. 

Обратите внимание на то, что математическое ожидание апостериорного распределения $\b$ очень сильно напоминает классическую МНК-оценку этого параметра. Новое значение параметра $\tilde k$,  в свою очередь напоминает МНК-оценку дисперсии для коэффициента $\beta$. Любителям консперологии и теорий различных заговоров на этом моменте пора бы погрузиться в глубокие думы, а также не забыть обвинить Томаса Байеса в масонстве и придумывании плана по захвату мира в 21 веке. Имейте в виду, если вы добросовестно изучите эту книгу, мы найдём вас и предложим пройти обряд по вступлению в наше тайное общество. По толпе собравшихся в нашем тайном месте пронесётся ропот: <<Постериор! Постериор!>> и на вашем теле появится тайный знак байесовцев. 


\section{А ты точно регрессия в STAN} 


\section{Регуляризация для самых маленьких}


\section{Регуляризация и байесовство} 


\section{Кросс-валидация без байеса} 


\section{Кросс-валидация с байесом} 


\section{Ещё раз про приемущества байесовских моделей} 


\section{Ещё задачи} 


\begin{problem}
	
	
	\begin{sol} 
		
		
	\end{sol} 
\end{problem}


\begin{problem}
	
	
	\begin{sol} 
		
		
	\end{sol} 
\end{problem}


\begin{problem}
	
	
	\begin{sol} 
		
		
	\end{sol} 
\end{problem}


\begin{problem}
	
	
	\begin{sol} 
		
		
	\end{sol} 
\end{problem}


\begin{problem}
	
	
	\begin{sol} 
		
		
	\end{sol} 
\end{problem}


\begin{problem}
	
	
	\begin{sol} 
		
		
	\end{sol} 
\end{problem}




















\section{Нет,  мама STAN не умеет делать борщ, но он может оценить регрессию} 

\todo[inline]{про рег}

Тем временем на подиум выходит следующая модель. Раздаются авации. Зал замирает. Красавица, вышедшая на подиум неузнаваема. Каждый чувствует в ней что-то родное, но не может понять кто она... Всему своё время, нужно просто как следует приглядеться. 

\section{О преимуществах байесовских моделей в машинном обучении}

Зайдём издалека. Пусть, как всегда, у нас есть выборка $(x_i, y_i)$. Как обычно у нас есть модель 


Пусть также $u_i \sim \mN(0, \sigma^2 \mid x)$. Это, в свою очередь, означает, что $y_i \sim \mN(\beta x_i, \sigma^2)$. Априорно будем считать, что $\b \sim \mN(0, \sigma^2)$.

Пусть в качестве точечной байесовской оценки мы собираемся взять апостериорную моду. Это означает, что мы решаем следующую задачу: 

Делаем уже до боли знакомый нам байесовский вывод

\[ f(\b \mid x,y, \sigma^2) \propto f(\b) \cdot f(y \mid \b, \sigma^2, x).\]

Сразу же прологорифмируем всё 


Уже знакомым нам дв


В тот самый момент, когда она достигла края подиума, толпа всё поняла. У этой красавицы много имён. Кто-то узнал в ней  Ridge, гребневая, линейная модель с $l_2$ регуляризатором --- это всё о ней. Авации возобновились. 

Наши предположения дали нам метод наименьших квадратов с $l_2$ регуляризатором. И без того известная нам модель может быть переформулирована на байесовском языке и соответствует достаточно простой вероятностной модели. Этот факт иллюстрирует одно из главных преимуществ байесовского подхода: 




% Куда блин это сунуть?! 
Кроме того, байесовские методы позволяют:

\begin{enumerate} 
\item Строить сложные вероятностные модели из более простых. Байесовский вывод одной модели можно использовать в качестве априорного распределения в следующей вероятностной модели. Так можно скреплять разные модели между собой и строить целые сети. 

\item Можно обрабатывать массивы данных, в которых информация поступает последовательно. При поступлении новой порции данных старое апостериорное распределение можно использовать как априорное без необходимости повторного обучения модели с нуля. 

\item Возможно использовать априорное распределение, которое предотвращает излишнюю настройку известных параметров на обучающую выборку, это в свою очередь позволяет избежать переобучения. 

\item Возможно работать не с полностью размеченными, частично размеченными и с вовсе не размеченными обучающими выборками. 

\end{enumerate}


% Написать про генеративные и дискриминативные модели


Самое время напрячься и решить парочку упражнений. В части упражнений, связанных с Ridge и Lasso-регрессиями нам снова придётся иметь дело со слонами. 

\subsection*{Упражнения} 

\begin{problem}
Упражнение с пересчётом с циферками
\begin{sol}

\end{sol}
\end{problem}

\begin{problem}
Рассмотрим модель
\[
y = X\beta + u,
\]
где $u_i$ независимы и $\mN(0; \sigma^2)$.

Метод гребневой регрессии предполагает минимизацию функции
\[
Q(\beta) = \sum_{i=1}^n (y_i - \hat y_i)^2 + \lambda \sum_{j=1}^k \beta_j^2.
\]

Рассмотрим байесовский подход к регрессии. Предположим, что априорное распределение имеет вид $\sigma^2 \sim InvGamma(s, r)$, $\beta_j|\sigma^2 \sim \mN(0; a(\sigma^2))$.

При каких $s$, $r$ и $a(\sigma^2)$ апостериорная мода $\hat\beta_{MAP}$ совпадёт с $\hat\beta_{Ridge}$?
\begin{sol}
\end{sol}
\end{problem}

\begin{problem}
Рассмотрим модель
\[
y = X\beta + u,
\]
где $u_i$ независимы и $\mN(0; \sigma^2)$.

Метод LASSO предполагает минимизацию функции
\[
Q(\beta) = \sum_{i=1}^n (y_i - \hat y_i)^2 + \lambda \sum_{j=1}^k |\beta_j|.
\]

Рассмотрим байесовский подход к регрессии. Предположим, что априорное распределение имеет вид $\sigma^2 \sim InvGamma(s, r)$, $\beta_j|\sigma^2 \sim DoubleExp(a(\sigma^2))$.

При каких $s$, $r$ и $a(\sigma^2)$ апостериорная мода $\hat\beta_{MAP}$ совпадёт с $\hat\beta_{LASSO}$?
\begin{sol}
  При любых $s$ и $r$, и $a(\sigma^2)=\lambda/2\sigma^2$
\end{sol}
\end{problem}


\begin{problem}
Упражнения про свойства гамма и экспоненциального распределений с википедии. 
\begin{sol}

\end{sol}
\end{problem}


\section{О том как связаны покемоны и регуляризация}

\begin{problem}
Храбрый Охотник ловит Покемонов в случайном порядке. Вес $i$-го пойманного Покемона, $y_i$, имеет нормальное распределение $\mN(\mu; \sigma^2)$. Параметры $\mu$ и $\sigma$ неизвестны.

Храбрый охотник хочет оценить $\mu$ по формуле $\hat\mu = c\sum_{i=1}^n y_i$.

\begin{enumerate}
\item При каком $c$ величина $\E((\hat\mu - \mu)^2)$ будет минимальна?
\item Возможно ли использовать на практике данное $c$?
\end{enumerate}
\begin{sol}
  $c=\frac{1}{n + \sigma^2/\mu^2}$, нет, так как $\mu$ и $\sigma^2$ неизвестны.
\end{sol}
\end{problem}



\section{Кросс-валидация без байеса}


\section{Кросс-валидация с байесом} 








% \Closesolutionfile{solution_file}
% \input{solutions1}

\end{document}
